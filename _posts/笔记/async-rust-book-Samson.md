# Asynchronous Programming in Rust

## Part I: 异步编程基础
### 1. Overview: 并发和异步
最开始是没有OS的，计算机的CPU，一个接一个地执行程序员编写的一组指令。（没有调度，没有线程，没有多任务） --> 简单的 OS （将整个CPU的运行权交给程序） --> 多任务

- 非抢占式多任务处理：一种计算机操作系统中的任务调度策略，任务在完成或自愿放弃CPU使用权之前不会被中断。需要程序员来决定多个程序之间的调度。
- 抢占式多任务处理：让OS来负责调度CPU资源。操作系统可以停止一个进程的执行，做其他事情，然后切换回来。

Hyper-threading: 随着CPU的发展和功能增加，如多个算术逻辑单元（alu）和额外的逻辑单元，CPU制造商意识到整个CPU没有得到充分利用。比如，当一条指令只需要CPU的某个部分时，另一条指令也能在ALU上运行

多核处理器

Do you really write synchronous code?
- 程序员视角：同步执行所有代码，一行接着一行
- OS 视角：它可能会（也可能不会）中断程序代码执行，暂停它，并在恢复您的进程之前同时运行一些其他代码。
- CPU 视角：负责执行一条指令。*它不关心是哪个程序*
    - 可以通过分支预测、乱序执行、特定功能的计算单元来加速

Async 历史

我们把同时处理多个任务的概念称为多任务。多任务处理有两种方法: 并发和并行
- Concurrency：并发是指同时处理很多事情。（但不是同一时间处理）
- parallelism：并行是指在同一时间做很多事情。

> Resource：完成任务需要的资源，可能是CPU/内存
> Task：这是一组需要某种资源才能进行的操作。一个任务必须由几个子操作组成。
> Parallel：这是在同一时刻独立发生的事情。
> Concurrent：这些是同时间段内进行的任务，但同一时刻不会一起进行。

**最重要的区别是：并发能提高资源的利用效率。并发永远不能使单个任务运行得更快。它只能帮助我们更好地利用我们的资源，从而更快地完成一组任务；并行只是增加资源，与资源利用效率无关。**

并发和IO的关系，两种场景：
- 当执行I/O并且需要等待一些外部事件发生时（网络IO）
- 当你需要分散注意力，防止一项任务等待太久时（UI刷新）


OS提供的线程：当使用操作系统线程来理解并发性时，一个挑战是它们似乎被映射到内核。这并不一定是一个正确的心智模型，即使大多数操作系统会尝试将一个线程映射到一个内核，直到线程数量等于内核数量。
- 1:1
- M:N
> 线程可以并发，也可以并行

选择合适的参考模型
- 程序员的视角
- OS 的视角：同步是一种假象，在背后会中断/恢复执行

参考框架：当我们在不提供任何其他上下文的情况下讨论并发性时，我们使用的是作为程序员的您和您的代码（您的进程）作为参考框架。

**异步编程是编程语言或库对并发操作的抽象方式，以及我们作为语言或库的用户如何使用这种抽象来并发地执行任务。**
- 操作系统已经有一个现有的抽象来涵盖这一点，称为线程。使用操作系统线程处理异步通常被称为多线程编程。为了避免混淆，我们将不把直接使用操作系统线程称为异步编程，尽管它解决了同样的问题。


OS视角下的并发：操作系统使用抢占式多任务处理，只要您正在运行的操作系统是抢占式调度进程，您就不能保证您的代码一条指令一条指令地运行而不中断。操作系统将确保所有重要的进程从CPU获得一些时间来取得进展。
- 通过系统调用 System Call 来和 OS 交互

1. CPU如何阻止我们访问我们不应该访问的内存?
- 虚拟内存和MMU
- Page Table、Page fault、Exceptions、Privilege Level 特权级别（用户空间、内核空间）

2. CPU如何处理异步事件，如I/O

中断、设备和IO

### 2. 异步程序流的编程语言模型
threads, futures, fibers, goroutines, promises 等都是对异步编程流的一种抽象。它们有不同的优点和缺点，但它们都有一个共同的目标，即为程序员提供一种易于使用（而且重要的是，难以误用）、高效和富有表现力的方式来创建一个以非顺序的、通常是不可预测的顺序处理任务的程序。

将并发操作的抽象模型分为两类：
- 协作式：task 当任务在另一个操作完成之前（例如进行网络调用）无法继续进行时，该函数会挂起任务，让出CPU。大多数情况下，这些任务由某种调度器完成。Rust和JavaScript中的async/await生成的任务属于这一类。
- 非协作式：调度器必须能够抢占正在运行的任务，这意味着调度器可以停止任务并控制CPU，即使任务已经能够完成工作和进度。例子是OS线程和了goroutine。

基于实现的特征来分为两类：
- Stackful：每个任务都有自己的调用堆栈。这通常被实现为一个堆栈，类似于操作系统为其线程使用的堆栈。堆栈任务可以在程序中的任何点暂停执行，因为整个堆栈被保留。
- Stackless：不是每个任务都有一个单独的堆栈；它们都共享同一个调用堆栈运行。任务不能在堆栈帧的中间挂起，这限制了运行时抢占任务的能力。然而，在任务之间切换时，它们需要存储/恢复的信息更少，因此它们可以更高效。

#### Threads
在最一般的意义上，线程指的是执行线程，意味着一组需要按顺序执行的指令。

分为两类：
- OS 线程：大多数现代操作系统上的操作系统线程有很多相似之处。大多数cpu都假定存在一个可以执行操作的堆栈，并且它有一个堆栈指针寄存器和堆栈操作指令。
- 用户线程：从最广泛的意义上讲，用户级线程可以指创建和调度任务的系统（运行时）的任何实现，您不能像对操作系统线程那样做出相同的假设。它们可以为每个任务使用单独的堆栈，这与操作系统线程非常相似，也可以使用与OS完全不一样的模型。

当有人在没有添加额外上下文的情况下提到“线程”时，他们指的是操作系统线程/内核线程。

继续将执行线程简单地称为任务。我发现，如果我们尽可能根据上下文限制使用具有不同假设的术语，那么异步编程的主题就更容易理解了。

有了这些，让我们来看看操作系统线程的一些定义特征，同时强调它们的局限性

OS 线程：1:1模型
- 操作系统线程很容易实现，也很容易使用。让OS负责一切，为每一个任务都生成一个线程来执行。



使用操作系统线程作为处理并发的一种手段，要求我们使用本质上是操作系统抽象的东西来表示我们的任务。


拥有一个单独的抽象层来表示并发任务，可以让我们自由选择如何处理并发操作。如果我们在并发操作上创建一个抽象，比如Rust中的future， JavaScript中的promise，或者GO中的gooutine，那么这些并发任务是由运行时实现者决定如何处理的。

运行时可以简单地将每个并发操作映射到一个操作系统线程，它们可以使用光纤/绿色线程或状态机来表示任务。如果底层实现发生变化，编写异步代码的程序员不必更改代码中的任何内容。从理论上讲，相同的异步代码可以用于处理没有操作系统的微控制器上的并发操作，如果它只有一个运行时。

线程
- 优点
    - 易于理解和使用
    - 任务切换较快
    - 免费获得并行性
- 缺点
    - 操作系统级别的线程有一个相当大的堆栈。如果你有很多任务同时等待，会很快耗尽内存
    - 上下文切换可能代价高昂，而且由于让操作系统执行所有调度，您可能会获得不可预测的性能。
    - 操作系统需要处理很多事情。它可能不会像您希望的那样快速切换回您的线程。
    - 它与操作系统抽象紧密耦合。这在某些系统上可能不是一个选项。

#### Green threads/stackfull coroutines/fibers
这是一个M:N线程的例子。许多任务可以并发地运行在一个操作系统线程上。fibers/Green threads通常被称为有栈协程。

“绿色线程”这个名称最初源于Java中使用的M:N线程模型的早期实现，此后与M:N线程的不同实现相关联。你会遇到不同的术语,如“绿色过程”(用于Erlang),不同于我们在这里讨论的。您还将看到一些对绿色线程的定义比这里更广泛。

我们在这本书中定义绿色线的方式使它们与 fiber  同义，所以这两个术语指的是同样的东西。

Green threads and fibers的实现意味着存在一个带有调度程序的运行时，该调度程序负责调度哪些任务(M)有时间在OS线程(N)上运行。任务比OS线程要多得多，这样的系统只使用一个OS线程就可以运行得很好。（M:1模型）

Goroutines是堆栈协同程序的一个具体实现示例，但它有一些细微的差别。术语“协程”通常意味着它们在本质上是协作的，但是 Goroutines 可以由调度器抢占，因此使用我们在这里介绍的类别，将它们置于某种灰色地带。

使用与操作系统相同的机制，为每个任务设置堆栈，保存CPU的状态，并通过上下文切换从一个任务（线程）跳转到另一个任务（线程）。


执行状态存储在每个堆栈中，因此在这样的解决方案中，不需要async、await、Future或Pin。在许多方面，绿色线程模仿操作系统如何促进并发性，实现它们是一个很好的学习经验。


使用Green threads and fibers执行并发任务的运行时具有高度的灵活性。例如，任务可以在执行过程中的任何时间和任何点被抢占和上下文切换，因此一个占用CPU的长时间运行任务理论上可以被运行时抢占，作为一种保护措施，防止由于边缘情况或程序员错误而导致任务最终阻塞整个系统

这为运行时调度器提供了与操作系统调度器几乎相同的功能，这是使用Green threads and fibers的系统的最大优点之一。

由于光纤和绿色线程类似于操作系统线程，它们也有一些相同的缺点。每个任务都设置了一个固定大小的堆栈，因此您仍然需要保留比实际使用更多的空间。然而，这些堆栈可以是可增长的，这意味着一旦堆栈满了，运行时就可以增长堆栈。虽然这听起来很简单，但这是一个相当复杂的问题。


我们不能像种树那样简单地增长堆栈。真正需要发生的是以下两件事之一：
- 您分配了一块新的连续内存，并处理堆栈分布在两个不相连的内存段上的事实
- 您分配一个新的更大的堆栈（例如，是前一个堆栈大小的两倍），将所有数据移动到新堆栈，并从那里继续

第一个解决方案听起来很简单，因为您可以保持原始堆栈不变，并且可以在需要时上下文切换到新堆栈并从那里继续。然而，由于缓存和预测下一个指令将要处理的数据的能力，如果现代cpu能够在连续的内存上工作，那么它们的工作速度就会非常快。将堆栈分散到两个不相连的内存中会影响性能。当循环恰好位于堆栈边界时，这一点尤其明显，因此您最终创建了最多两个上下文


第二种解决方案通过将堆栈作为一个连续的内存块来解决第一种解决方案的问题，但它也有一些问题。

首先，您需要分配一个新堆栈并将所有数据移动到新堆栈。但是，当所有指针和引用都移动到一个新位置时，指向堆栈上某个位置的指针和引用会发生什么呢？您猜对了：每个指向堆栈上任何东西的指针和引用都需要更新，以便它们指向新的位置。这是复杂和耗时的，但是如果您的运行时已经包含了一个垃圾收集器，那么无论如何，您已经有了跟踪所有指针和引用的开销，因此这可能比使用非垃圾收集器要少一些问题


其次，如果您有很多长时间运行的任务，这些任务只在很短的一段时间内需要大量的堆栈空间（例如，如果它在任务开始时涉及大量递归），但其余时间大多是I/O受限，那么您必须考虑会发生什么。最终，仅针对该任务的一个特定部分，您就会多次增加堆栈，并且您必须做出决定，是接受任务占用的空间超过其所需的空间，还是在某个时候将其移回更小的堆栈。这将对您的程序产生的影响当然会因不同而有很大的不同

尽管与OS线程相比，这些光纤/绿色线程是轻量级的，但您仍然需要在每次上下文切换时保存和恢复寄存器。大多数情况下，这可能不是问题，但是与不需要上下文切换的替代方案相比，它的效率可能会降低。

上下文切换也可能非常复杂，特别是如果您打算支持许多不同的平台


当一个光纤/绿色线程向运行时调度器屈服时，调度器可以简单地在准备运行的新任务上恢复执行。这意味着您可以避免每次屈服于调度器时与系统中的所有其他任务被放在同一个运行队列中的问题。从操作系统的角度来看，您的线程一直在忙着做工作，因此如果可以的话，它将尽量避免抢占它们。

这样做的一个意想不到的缺点是，大多数操作系统调度器通过在操作系统抢占线程并在该CPU上调度新线程之前给每个操作系统线程一个可以运行的时间片来确保所有线程都有时间运行。使用许多操作系统线程的程序可能会比使用较少操作系统线程的程序分配更多的时间片。使用M:N线程的程序很可能只使用几个操作系统线程（在大多数系统上，每个CPU核心一个线程似乎是起点）。因此，取决于系统上运行的其他东西，您的程序在t中分配的时间片可能更少


由于您创建了自己的堆栈，这些堆栈应该在某些条件下增长/缩小，并且可能有一个调度程序，假设它可以在任何时候抢占正在运行的任务，因此在使用FFI时必须采取额外的措施。大多数FFI函数将假设一个正常的操作系统提供的c堆栈，所以从光纤/绿色线程调用FFI函数很可能会有问题。您需要通知运行时调度器，上下文切换到不同的操作系统线程，并以某种方式通知调度器您已经完成，并且光纤/绿色线程可以继续。这自然会造成过度



优点：
- 它对用户来说使用起来很简单。代码看起来就像使用OS线程时一样。
- 上下文切换相当快。
- 与操作系统线程相比，大量内存使用不是什么问题。
- 你完全可以控制任务的安排，如果你想的话，你可以根据自己的需要优先安排任务。
- 它很容易进行抢占式调度，这可能是一个强大的功能。

缺点：
- 当栈的空间不够时，它们需要一种方式来增长，从而产生额外的工作和复杂性
- 您仍然需要保存每次上下文切换时的CPU状态
- 如果你打算支持多个平台和/或CPU架构，这会很复杂
- FFI可能有很多开销，并增加了意想不到的复杂性

#### Callback based approaches
这是另一个M:N线程的例子。许多任务可以并发地运行在一个操作系统线程上。每个task都是一个call back chain

基于回调的方法背后的整个思想是保存一个指向一组指令的指针，我们希望稍后运行这些指令，以及所需的任何状态。在Rust中，这将是一个闭包。

在大多数语言中实现回调相对容易。它们不需要任何上下文切换或为每个任务预先分配内存。

然而，使用回调来表示并发操作要求您从一开始就以一种完全不同的方式编写程序。将一个使用正常顺序程序流的程序重写为一个使用回调的程序，这是一种实质性的重写，反之亦然。

基于回调的并发性可能很难推理，并且可能变得非常复杂而难以理解。大多数JavaScript开发人员都熟悉“回调地狱”这个术语，这并非巧合。

由于每个子任务必须保存以后所需的所有状态，因此内存使用将随着任务中回调的数量线性增长。

优点
- 易于在大多数语言中实现
- No context switching
- Relatively low memory overhead (in most cases)

缺点：
- 内存使用量随着回调次数的增加呈线性增长。
- 程序和代码可能很难推理
- 这是一种非常不同的编写程序的方式，它将影响程序的几乎所有方面，因为所有生成操作都需要一个回调。
- 所有权是很难解释的。其结果是，编写没有垃圾收集器的基于回调的程序会变得非常困难。
- 由于所有权规则的复杂性，任务之间的状态共享变得困难。
- Debugging callbacks can be difficult.

#### Coroutines: promises and futures
M: N个线程。许多任务可以并发地运行在一个操作系统线程上。每个任务都表示为一个状态机。

promise 是处理基于回调方法带来的复杂性的一种方法。

promise返回一个状态机，该状态机可以处于以下三种状态之一：挂起、完成或拒绝。


协程有两种形式：不对称和对称。非对称协程产生了调度程序，它们是我们将要关注的。对称协程产生一个特定的目标；例如，一个不同的协程。

虽然协程通常是一个相当广泛的概念，但在编程语言中将协程作为对象引入，才是真正使这种处理并发的方式与操作系统线程和纤维/绿色线程的易用性相媲美的原因。


当你在Rust或JavaScript中编写异步时，编译器会将看起来像普通函数调用的内容重写为future（在Rust中）或promise（在JavaScript中）。另一方面，Await将控制权交给运行时调度器，任务被挂起，直到您正在等待的future/ promise完成

这样，我们就可以编写处理并发操作的程序，其方式与编写常规顺序程序的方式几乎相同

在任何无堆栈协程实现中，完全抢占很难实现，甚至不可能实现。这些函数必须在特定的点产生，并且与光纤/绿色线程相比，没有办法在堆栈帧的中间暂停执行。例如，通过让运行时或编译器在每个函数调用中插入抢占点，可以实现某种程度的抢占，但这与能够在执行过程中的任何点抢占任务是不一样的。

此外，您需要编译器支持来充分利用它。具有元编程能力的语言（如宏）可以模拟大部分相同的功能，但这仍然不会像编译器意识到这些特殊的异步任务时那样无缝。

调试是实现未来/承诺时必须注意的另一个领域。由于代码被重新编写为状态机（或生成器），因此不会像使用普通函数那样具有相同的堆栈跟踪。通常，您可以假设函数的调用者在堆栈和程序流中都位于它之前。对于未来和承诺，可能是运行时调用了使状态机前进的函数，因此可能没有一个好的回溯可以用来查看调用失败的函数之前发生了什么。有很多方法可以解决这个问题，


优点：
- 您可以像往常一样编写代码并为程序建模
- No context switching
- 它可以以一种非常节省内存的方式实现
- 它很容易在各种平台上实现

缺点：
- 抢占很难或不可能完全实现，因为任务不能在堆栈帧的中间停止
- 它需要编译器的支持才能充分利用其优势
- 由于非顺序的程序流和从回溯中获得的信息的限制，调试可能会很困难。



### 3. 理解 OS-Backed Event Queues, System Calls and Cross Platform Abstractions
我们将了解操作系统支持的事件队列是如何工作的，以及三种不同的操作系统如何以不同的方式处理此任务。这样做的原因是，我所知道的大多数异步运行时都使用这样的操作系统支持的事件队列作为实现高性能I/O的基本部分。在阅读异步代码的实际工作原理时，您很可能会经常听到这些内容。

- mio：Tokio
- polling：the event queue used in Smol and async-std
- libuv：the library used to create the event queue used in Node.js(a JavaScript runtime) and the Julia programming language
- C# for its asynchronous network calls
- Boost.Asio, a library for asynchronous network I/O for C++

#### Why use an OS-backed event queue?
您现在已经知道，我们需要与操作系统密切合作，以使I/O操作尽可能高效。Linux、macOS和Windows等操作系统提供了几种执行I/O的方式，包括阻塞和非阻塞。

I/O操作需要经过操作系统，因为它们依赖于我们的操作系统抽象的资源。这可以是磁盘驱动器、网卡或其他外设。
特别是在网络调用的情况下，我们不仅依赖于我们自己的硬件，而且还依赖于可能远离我们自己的资源，从而导致严重的延迟。

在前一章中，我们介绍了编程时处理异步操作的不同方法，虽然它们都不同，但它们都有一个共同点：它们需要控制何时以及是否在进行系统调用时屈服于操作系统调度器。

在实践中，这意味着需要避免通常会屈服于操作系统调度器（阻塞调用）的系统调用，而我们需要使用非阻塞调用。我们还需要一种有效的方法来了解每个调用的状态，这样我们就可以知道发出阻塞调用的任务何时准备好进行。这就是在异步运行时中使用操作系统支持的事件队列的主要原因。

阻塞IO：当我们要求操作系统执行阻塞操作时，它将挂起发出调用的操作系统线程。然后，它将存储在我们进行调用时的CPU状态，并继续做其他事情。当数据通过网络到达时，它将再次唤醒我们的线程，恢复CPU状态，并让我们继续，就像什么都没有发生一样。

阻塞操作对于我们程序员来说是最不灵活的，因为我们把控制权交给了操作系统。最大的优点是，一旦我们等待的事件准备好，我们的线程就会被唤醒，这样我们就可以继续了。如果我们考虑到整个系统在操作系统上运行，这是一个相当有效的解决方案，因为操作系统会给有工作要做的线程在CPU上的时间来进行。然而，如果我们缩小范围，孤立地观察我们的进程，我们会发现，每次我们进行阻塞调用时，我们都会让一个线程进入睡眠状态，即使我们仍然有工作要处理

非阻塞IO：与阻塞I/O操作不同，操作系统不会挂起发出I/O请求的线程，而是给它一个句柄，线程可以用它来询问操作系统事件是否准备好了。

非阻塞I/O操作给了我们程序员更多的自由，但是，像往常一样，随之而来的是责任。如果我们过于频繁地轮询，例如在循环中，我们将占用大量CPU时间来请求更新状态，这是非常浪费的。如果我们的轮询频率太低，那么在事件准备就绪和我们对它做一些事情之间就会有明显的延迟，从而限制了我们的吞吐量。



#### event queues
这是前面几种方法的一种混合。在网络调用的情况下，调用本身将是非阻塞的。但是，我们可以将句柄添加到事件队列中，而不是定期轮询句柄，并且我们可以使用数千个句柄来完成此操作，开销很小。

作为程序员，我们现在有了一个新的选择。我们可以定期查询队列以检查我们添加的任何事件是否改变了状态，或者我们可以对队列进行阻塞调用，告诉操作系统我们希望在队列中至少有一个事件改变状态时被唤醒，以便等待该特定事件的任务可以继续。

这允许我们仅在没有更多工作要做并且所有任务都在等待事件发生时才将控制权交给操作系统。我们可以自己决定什么时候发出这样一个阻塞调用

Readiness-based event queues：Epoll和kqueue被称为基于就绪性的事件队列，这意味着它们让您知道何时可以执行某个操作。这方面的一个例子是准备从中读取的套接字。
![alt text](/images/async-rust-book-Samson/image.png)

Completion-based event queues：IOCP代表输入/输出完成端口。这是一个基于完成的事件队列。这种类型的队列在事件完成时通知您。这样的一个例子是当数据被读入缓冲区时。
![alt text](/images/async-rust-book-Samson/image-1.png)


![alt text](/images/async-rust-book-Samson/image-2.png)

#### Syscalls, FFI, and cross-platform abstractions
当创建一个跨平台事件队列时，你必须处理这样一个事实：你必须创建一个统一的API，无论它是在Windows (IOCP), macOS （kqueue）还是Linux （epoll）上使用，它都是一样的。最明显的区别是IOCP是基于完成的，而kqueue和epoll是基于就绪的。

这种根本的区别意味着你必须做出选择：
- 您可以创建一个抽象，将kqueue和epoll视为基于完成的队列，或者
- 您可以创建一个抽象，将IOCP视为基于就绪性的队列

从我个人的经验来看，创建一个抽象来模拟基于完成的队列，并处理kqueue和epoll在幕后基于就绪的事实，要比其他方式容易得多。正如我前面提到的，使用wepoll是在Windows上创建基于就绪性的队列的一种方法。它将极大地简化创建这样一个API的过程，但我们现在将把它放在这里，因为它不太为人所知，而且微软也没有正式记录这种方法。


由于IOCP是基于完成的，它需要一个缓冲区来读取数据，因为当数据被读取到该缓冲区时它会返回。另一方面，Kqueue和epoll不需要这个。只有当您可以将数据读取到缓冲区而不阻塞时，它们才会返回。


通过要求用户向我们的API提供他们喜欢的大小的缓冲区，我们让用户控制他们想要如何管理他们的内存。当使用IOCP时，用户定义缓冲区的大小，重用和控制将传递给操作系统的内存的所有方面


在这种API中使用epoll和kqueue的情况下，您可以简单地为用户调用read并填充相同的缓冲区，从而使用户认为API是基于完成的。


如果你想要呈现一个基于就绪性的API，你就必须在Windows上做I/O的时候创造一种有两个独立操作的错觉。首先，在套接字上准备读取数据时请求通知，然后实际读取数据。虽然可能这样做，但你很可能会发现自己不得不创建一个非常复杂的API，或者在Windows平台上接受一些低效率，因为有中间缓冲区来保持具有基于就绪性的API的错觉。


我们将把事件队列的主题留到创建一个简单示例时再讨论，以展示事件队列的工作原理。在我们这样做之前，我们需要真正熟悉FFI和系统调用，我们将通过在三个不同的平台上编写一个系统调用的示例来实现这一点。

我们还将利用这个机会讨论抽象级别，以及如何创建在三个不同平台上工作的统一API。


最低级别的抽象是编写通常称为“原始”系统调用的内容。原始系统调用是绕过操作系统提供的库来进行系统调用，而是依赖于操作系统具有稳定的系统调用ABI。稳定的系统调用ABI意味着，如果您将正确的数据放入特定的寄存器中，并调用将控制传递给操作系统的特定CPU指令，那么它将始终执行相同的操作

要进行原始的系统调用，我们需要编写一些inline assembly，但不用担心。尽管我们在这里很突然地介绍它，但我们将逐行介绍它，在第5章中，我们将更详细地介绍内联汇编，以便您熟悉它。

在这个抽象层次上，我们需要为BSD/macOS、Linux和Windows编写不同的代码。如果操作系统运行在不同的CPU架构上，我们还需要编写不同的代码。


在Linux和macOS上，我们想要调用的系统调用称为write。这两个系统都基于文件描述符的概念进行操作，并且在启动进程时标准输出已经存在。

我们要做的第一件事是拉入标准库模块，它使我们能够访问asm！宏。`use std::arch::asm;`

```rust
#[inline(never)]
fn syscall(message: String) {
    let msg_ptr = message.as_ptr();
    let len = message.len();
    unsafe {
        asm!(
        "mov rax, 1",
        "mov rdi, 1",
        "syscall",
        in("rsi") msg_ptr,
        in("rdx") len,
        out("rax") _,
        out("rdi") _,
        lateout("rsi") _,
        lateout("rdx") _
    );
    }
}
```

## Part II: Event Queues and Green Threads

### 4. Create Your Own Event Queue

### 5. Creating Our Own Fibers


## Part III: Futures and async/await in Rust
### 6. Futures in Rust
### 7. Coroutines and async/await

### 8. Runtimes, Wakers, and the Reactor-Executor Pattern

### 9. Coroutines, Self-Referential Structs, and Pinning

### 10. Creating Your Own Runtime



